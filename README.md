# Instruction Tuning GPT2 on Alpaca Dataset
- Author: Sovit Ranjan Rath _ May 6, 2024
- Practice: Mr. Jack _ May30, 2024
- Link: https://debuggercafe.com/instruction-tuning-gpt2-on-alpaca-dataset/

Fine-tuning language models to follow instructions is a major step in making them more useful. In this article, we will train the GPT2 model for following simple instructions. Instruction tuning GPT2 on the Alpaca dataset will reveal how well very small language models perform at following instructions.

In particular, we will train the GPT2 base model which contains just 124 million parameters. This is much smaller than what the industry considers as SLMs (Small Language Models), which us typically 7 bllion (7B) parameters. In fact, any language model below 3 billion parameters can be a challenge to to train for instruction following. However, in future posts, we will train many such models and see how far we can push the envelope forward. This post is a starting point for this.

~> HÃ´m qua (29 May 2024) tÃ¬m tháº¥y Ä‘Æ°á»£c má»™t chá»§ Ä‘á» hay nÃªn pháº£i báº¯t tay vÃ o thá»±c hÃ nh ngay, káº¿t quáº£ ráº¥t tuyá»‡t ^^ . Há»“i trÆ°á»›c mÃ¬nh chá»‰ thÃ­ch thuáº­t toÃ¡n AI , khÃ´ng thÃ­ch lÃ m giao diá»‡n (UI/UX), khÃ´ng thÃ­ch lÃ m Data, ... khÃ´ng thÃ­ch nÃ y ná» ... giá» khi lÃ m demo AI lÃ  vÆ°á»›ng toÃ n diá»‡n khÃ´ng chá»«a má»¥c nÃ o, tá»« a-z, nÃªn va vÃ o cÃ¡i nÃ o ngáº¥t luÃ´n cÃ¡i Ä‘Ã³ ğŸ˜‚ ... mÃ¬nh cÅ©ng Ä‘ang pháº£i Ã´n táº­p láº¡i má»™t sá»‘ ná»™i dung cÆ¡ báº£n cá»§a Javascript, UI/UX, Gradio, Dataset ... vÃ¬ náº¿u khÃ´ng thÃ´ng máº¥y cÃ¡i nÃ y mÃ  copy-paste source code cá»§a tÃ¢y vá» thá»­ mÃ  nÃ³ khÃ´ng cháº¡y á»Ÿ má»™t chá»— nÃ o Ä‘Ã³, vÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³ thÃ¬ chá»‰ cÃ³ ngá»“i khÃ³c báº±ng tiáº¿ng mÃ¡n ğŸ˜‚ <br><br>

~> Vá»›i example nÃ y, máº·c dÃ¹ mÃ¬nh Ä‘Ã£ copy y nguyÃªn source code cá»§a tÃ¡c giáº£ nhÆ°ng ... váº«n bá»‹ lá»—i :( lÃºc Ä‘áº§u thÃ¬ cÅ©ng chÆ°a tin lÃ  source code cá»§a tÃ¡c giáº£ bá»‹ lá»—i Ä‘Ã¢u, nhÆ°ng thá»­ nghiá»‡m vÃ i láº§n váº«n bá»‹ lá»—i nÃªn thÃ nh ra pháº£i fix láº¡i má»™t vÃ i chá»—, sau hÆ¡n 1 ngÃ y lÃ m viá»‡c thÃ¬ cÅ©ng Ä‘Ã£ xá»­ lÃ½ xong ^^ <br>
~> Äá»ƒ thá»ƒ hiá»‡n sá»± tÃ´n trá»ng Ä‘á»‘i vá»›i tÃ¡c giáº£, mÃ¬nh Ä‘á»ƒ nguyÃªn pháº§n code báº£n gá»‘c, chá»‰ rÃ o láº¡i vÃ  thÃªm pháº§n code sá»­a láº¡i á»Ÿ ngay dÆ°á»›i Ä‘á»ƒ váº«n Ä‘áº£m báº£o source code cháº¡y Ä‘Æ°á»£c vÃ  ngÆ°á»i Ä‘á»c váº«n follow Ä‘Æ°á»£c pháº§n source code nguyÃªn báº£n ban Ä‘áº§u cá»§a tÃ¡c giáº£ ^^ <br>

### Tham kháº£o:
- https://huggingface.co/docs
- https://pytorch.org/tutorials/index.html
